{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "827803c0-1d34-45d1-8c62-1f060b6866ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports and GPU Setup\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# GPU Check\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98d8cad4-0e12-43bf-835a-3db96d17404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Dataset Preparation\n",
    "\n",
    "df = pd.read_csv(\"Cleaned_Expanded_Students_Grading_Dataset.csv\")\n",
    "\n",
    "selected_features = [\n",
    "    'Attendance (%)', 'Midterm_Score', 'Final_Score', 'Assignments_Avg',\n",
    "    'Quizzes_Avg', 'Participation_Score', 'Projects_Score', 'Total_Score',\n",
    "    'Stress_Level (1-10)', 'Sleep_Hours_per_Night', 'life_satisfaction',\n",
    "    'has_close_friends', 'is_bullied', 'disrespected_by_peers', 'participates_in_activities'\n",
    "]\n",
    "\n",
    "df_subset = df.sample(n=2000, random_state=42).reset_index(drop=True)\n",
    "student_profiles = df_subset[['Student_ID'] + selected_features].copy()\n",
    "binary_columns = ['has_close_friends', 'is_bullied', 'disrespected_by_peers', 'participates_in_activities']\n",
    "for col in binary_columns:\n",
    "    student_profiles[col] = student_profiles[col].map({'Yes': 1, 'No': 0})\n",
    "student_profiles.fillna(0, inplace=True)\n",
    "student_profiles.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Initialize environment before model loading\n",
    "env = StudentAllocationEnv(student_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "524fff85-704e-4034-9a76-9532290fc657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Environment Class\n",
    "\n",
    "class StudentAllocationEnv:\n",
    "    def __init__(self, student_profiles, num_classrooms=10):\n",
    "        self.student_profiles = student_profiles\n",
    "        self.num_students = len(student_profiles)\n",
    "        self.num_classrooms = num_classrooms\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.unassigned_students = list(range(self.num_students))\n",
    "        self.classrooms = {i: [] for i in range(self.num_classrooms)}\n",
    "        random.shuffle(self.unassigned_students)\n",
    "        self.current_student_idx = self.unassigned_students.pop()\n",
    "        return self.get_state()\n",
    "\n",
    "    def get_state(self):\n",
    "        student_features = self.student_profiles.iloc[self.current_student_idx].drop('Student_ID').values\n",
    "        return torch.tensor(student_features, dtype=torch.float32, device=device)\n",
    "\n",
    "    def step(self, action):\n",
    "        classroom_id = action\n",
    "        self.classrooms[classroom_id].append(self.current_student_idx)\n",
    "        reward = self.calculate_reward(classroom_id)\n",
    "        done = len(self.unassigned_students) == 0\n",
    "        if not done:\n",
    "            self.current_student_idx = self.unassigned_students.pop()\n",
    "        next_state = self.get_state() if not done else None\n",
    "        return next_state, reward, done\n",
    "\n",
    "    def calculate_reward(self, classroom_id):\n",
    "        reward = 0\n",
    "        classroom_students = self.classrooms[classroom_id]\n",
    "        if len(classroom_students) < 2:\n",
    "            return 0\n",
    "\n",
    "        current_student = self.student_profiles.iloc[self.current_student_idx]\n",
    "        friends_in_class, bullied_in_class, disrespect_in_class = 0, 0, 0\n",
    "        total_scores, stress_levels, life_satisfactions = [], [], []\n",
    "\n",
    "        for idx in classroom_students:\n",
    "            student = self.student_profiles.iloc[idx]\n",
    "            total_scores.append(student['Total_Score'])\n",
    "            stress_levels.append(student['Stress_Level (1-10)'])\n",
    "            life_satisfactions.append(student['life_satisfaction'])\n",
    "            if current_student['has_close_friends'] == 1 and student['has_close_friends'] == 1:\n",
    "                friends_in_class += 1\n",
    "            if current_student['is_bullied'] == 1 and student['has_close_friends'] == 1:\n",
    "                bullied_in_class += 1\n",
    "            if current_student['disrespected_by_peers'] == 1 and student['disrespected_by_peers'] == 1:\n",
    "                disrespect_in_class += 1\n",
    "\n",
    "        avg_total_score = np.mean(total_scores)\n",
    "        avg_stress = np.mean(stress_levels)\n",
    "        avg_life_satisfaction = np.mean(life_satisfactions)\n",
    "\n",
    "        reward += 10 * friends_in_class\n",
    "        reward += 10 * bullied_in_class\n",
    "        if 60 <= avg_total_score <= 80:\n",
    "            reward += 5\n",
    "        if 4 <= avg_stress <= 7 and avg_life_satisfaction >= 5:\n",
    "            reward += 5\n",
    "        reward -= 10 * disrespect_in_class\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbc4a79c-f896-484d-9e94-5ad809f6cd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Q-Network & Agent\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, action_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, learning_rate=0.001, gamma=0.99, epsilon_start=1.0, epsilon_end=0.1, epsilon_decay=0.995):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon_start\n",
    "        self.epsilon_min = epsilon_end\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.model = QNetwork(state_size, action_size).to(device)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        with torch.no_grad():\n",
    "            return torch.argmax(self.model(state)).item()\n",
    "\n",
    "    def train(self, state, action, reward, next_state, done):\n",
    "        state = state.unsqueeze(0)\n",
    "        if next_state is not None:\n",
    "            next_state = next_state.unsqueeze(0)\n",
    "\n",
    "        q_values = self.model(state)\n",
    "        q_target = q_values.clone().detach()\n",
    "        if done:\n",
    "            q_target[0, action] = reward\n",
    "        else:\n",
    "            next_q_values = self.model(next_state)\n",
    "            q_target[0, action] = reward + self.gamma * torch.max(next_q_values).item()\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.loss_fn(q_values, q_target)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6e44e8b-cdd4-42df-9c67-dcef137a7c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hany_\\AppData\\Local\\Temp\\ipykernel_60168\\3899352680.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  agent.model.load_state_dict(torch.load('classroom_allocation_dqn_model_final.pth'))\n"
     ]
    }
   ],
   "source": [
    "# 5. Load Trained Model\n",
    "\n",
    "state_size = env.get_state().shape[0]\n",
    "action_size = env.num_classrooms\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "agent.model.load_state_dict(torch.load('classroom_allocation_dqn_model_final.pth'))\n",
    "agent.model.eval()\n",
    "print(\"Trained model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27dde5b0-6449-4c8a-8fb2-a3c2d9a556b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Sample Allocation Test\n",
    "\n",
    "# Allocate a few students using trained model\n",
    "\n",
    "def test_allocation(env, agent, num_students=10):\n",
    "    env.reset()\n",
    "    assigned = []\n",
    "    for _ in range(num_students):\n",
    "        state = env.get_state()\n",
    "        action = agent.get_action(state)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        student_id = env.student_profiles.iloc[env.current_student_idx]['Student_ID']\n",
    "        assigned.append((student_id, action))\n",
    "        if done:\n",
    "            break\n",
    "    return assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "148d474e-eb78-4756-a0ab-6fae7d0f87d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Allocations:\n",
      "Student 20588.0 → Classroom 9\n",
      "Student 6657.0 → Classroom 8\n",
      "Student 16068.0 → Classroom 4\n",
      "Student 9388.0 → Classroom 4\n",
      "Student 15870.0 → Classroom 8\n",
      "Student 1785.0 → Classroom 9\n",
      "Student 17222.0 → Classroom 5\n",
      "Student 1098.0 → Classroom 7\n",
      "Student 19234.0 → Classroom 3\n",
      "Student 6365.0 → Classroom 2\n"
     ]
    }
   ],
   "source": [
    "# Run test\n",
    "allocations = test_allocation(env, agent, num_students=10)\n",
    "print(\"\\nSample Allocations:\")\n",
    "for sid, cls in allocations:\n",
    "    print(f\"Student {sid} → Classroom {cls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137fbe7f-685e-4299-996f-01adea1cb672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
